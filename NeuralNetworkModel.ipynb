{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laasyagudisa/ML_Assignments_Data/blob/main/NeuralNetworkModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries"
      ],
      "metadata": {
        "id": "2q4HmJQTGQDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "PPb6Aq2sGalu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLwPzS7tSOex",
        "outputId": "0d134c02-64f5-451e-eb75-41a1b6f354b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "Z4uGlLdLGj8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "\n",
        "\n",
        "df = pd.concat([X,y],axis=1)"
      ],
      "metadata": {
        "id": "0cQ4D2zgZS2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define NeuralNetwork Class\n",
        "* Class definition includes activation, learning_rate, input_size, hidden_layer_size, and output_layer_size\n",
        "* Methods defined include forward pass and back-propagation, using *Stochastic Gradient Descent*"
      ],
      "metadata": {
        "id": "2Nfwpk9WGtvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NNClassifier:\n",
        "    def __init__(self, activation, learn_rate, input_neurons, hidden_neurons=2, output_neurons=1):\n",
        "        self.activation = activation\n",
        "        self.learn_rate = learn_rate\n",
        "        self.input_neurons = input_neurons\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.output_neurons = output_neurons\n",
        "\n",
        "        self.input_weights = np.random.randn(input_neurons, hidden_neurons)\n",
        "        self.hidden_weights = np.random.randn(hidden_neurons, output_neurons)\n",
        "        self.hidden_bias = np.zeros((1, hidden_neurons))\n",
        "        self.output_bias = np.zeros((1, output_neurons))\n",
        "\n",
        "    @staticmethod\n",
        "    def pre_process(mydata):\n",
        "        newdata = mydata.copy()\n",
        "        newdata = newdata.drop_duplicates()\n",
        "        newdata = newdata.dropna()\n",
        "        label_encoder = LabelEncoder()\n",
        "        for column in newdata.columns:\n",
        "            if newdata[column].dtype == 'object':\n",
        "                newdata[column] = label_encoder.fit_transform(mydata[column])\n",
        "        return newdata\n",
        "\n",
        "    @staticmethod\n",
        "    def split(X, Y):\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "    def forward_act(self, X):\n",
        "        if self.activation == 'sigmoid':\n",
        "            X = np.clip(X,-500,500) #stops overflow and underflow errors\n",
        "            return 1 / (1 + np.exp(-X)) #sigmoid function\n",
        "        elif self.activation == 'tanh':\n",
        "            return np.tanh(X)  #tanh function\n",
        "        else:\n",
        "            return np.maximum(0, X) #relu function\n",
        "\n",
        "    def backward_act(self, X):\n",
        "        if self.activation == 'sigmoid':\n",
        "            return X * (1 - X)  # Derivative of sigmoid\n",
        "        elif self.activation == 'tanh':\n",
        "            return 1 - X ** 2  # Derivative of tanh\n",
        "        else:\n",
        "            return np.where(X > 0, 1, 0)  # Derivative of ReLU\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.hidden = self.forward_act(np.dot(X, self.input_weights) + self.hidden_bias)\n",
        "        self.output = self.forward_act(np.dot(self.hidden, self.hidden_weights) + self.output_bias)\n",
        "        return np.round(self.output)\n",
        "\n",
        "    def backward_prop(self, X, Y):\n",
        "        error = Y - np.round(self.output)\n",
        "        delta_output = error * self.backward_act(self.output)\n",
        "        error_hidden = delta_output.dot(self.hidden_weights.T)\n",
        "        delta_hidden = error_hidden * self.backward_act(self.hidden)\n",
        "\n",
        "        # Update weights and biases using SGD\n",
        "        self.hidden_weights += self.hidden.T.dot(delta_output) * self.learn_rate\n",
        "        self.input_weights += X.T.dot(delta_hidden) * self.learn_rate\n",
        "        self.output_bias += np.sum(delta_output, axis=0, keepdims=True) * self.learn_rate\n",
        "        self.hidden_bias += np.sum(delta_hidden, axis=0, keepdims=True) * self.learn_rate\n",
        "\n",
        "    def training(self, X, Y, num_iter):\n",
        "        for i in range(num_iter):\n",
        "            for x, y in zip(X, Y):\n",
        "                x = x.reshape(1, -1)\n",
        "                y = y.reshape(1, -1)\n",
        "                #Forward and backward pass for each data point\n",
        "                self.forward(x)\n",
        "                self.backward_prop(x, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)"
      ],
      "metadata": {
        "id": "3pVRoKQQHIIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = NNClassifier.pre_process(df)\n",
        "y = df['Diagnosis']\n",
        "X = df.drop('Diagnosis', axis=1)"
      ],
      "metadata": {
        "id": "p0pqUO3NTFVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation\n",
        "* Clean input data *(data cleaner built into NN Class)*\n",
        "* Split train/test sets"
      ],
      "metadata": {
        "id": "nARrXKGzI4CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = NNClassifier.split(X, y)"
      ],
      "metadata": {
        "id": "gIG9qGHnbgre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create and Train NN Classifier Model"
      ],
      "metadata": {
        "id": "n2wDq8iRLPMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NNClassifier('signmoid', 0.001, 30, 15, 1)\n",
        "nn.training(X_train.values, Y_train.values, 1000)"
      ],
      "metadata": {
        "id": "qVoi8sYsLb3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Model Accuracy"
      ],
      "metadata": {
        "id": "ps14e6kiLnAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = np.round(nn.predict(X_train))\n",
        "train_accuracy = accuracy_score(Y_train, Y_pred)\n",
        "test_accuracy = accuracy_score(Y_test, np.round(nn.predict(X_test)))\n",
        "print(\"The training and testing accuracy : \")\n",
        "print(f'\\tTraining Accuracy: {train_accuracy:.5f}')\n",
        "print(f'\\tTesting  Accuracy: {test_accuracy:.5f}')"
      ],
      "metadata": {
        "id": "XBMFsmGJL5ss",
        "outputId": "6d3a25dc-253d-491f-c628-1bb13b2271ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training and testing accuracy : \n",
            "\tTraining Accuracy: 0.63956\n",
            "\tTesting  Accuracy: 0.57895\n"
          ]
        }
      ]
    }
  ]
}